{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2: Bias in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this assignment is to identify potential biases with the volume and quality of English Wikipedia articles about politicians, across many different countries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two external data sources were used for this assignment and they are both stored in the `data` subdirectory of this repository. The first external data source is a CSV file storing minimal information about ~50,000 Wikipedia articles about politicians (\"page_data.csv\"), which can be downloaded at https://figshare.com/articles/Untitled_Item/5513449. The second external data source is another CSV file storing ~200 countries/continents and their populations (\"WPDS_2018_data.csv\"), which can be downloaded at https://www.dropbox.com/s/5u7sy1xt7g0oi2c/WPDS_2018_data.csv?dl=0.\n",
    "\n",
    "The schemas for the CSV files are as follows:\n",
    "\n",
    "**page_data.csv**\n",
    "\n",
    "|column |description                                          |\n",
    "|-------|-----------------------------------------------------|\n",
    "|page   |name of Wikipedia article                            |\n",
    "|country|country of politician the Wikipedia article is about |\n",
    "|rev_id |revision ID of the last edit to the Wikipedia article|\n",
    "\n",
    "**WPDS_2018_data.csv**\n",
    "\n",
    "|column                        |description                                             |\n",
    "|------------------------------|--------------------------------------------------------|\n",
    "|Geography                     |country or contintent                                   |\n",
    "|Population mid-2018 (millions)|population of country or continent in millions of people|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Retrieving article quality predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict an article's quality, we are using the Object Revision Evaluation Service ([ORES](https://www.mediawiki.org/wiki/ORES)) API provided by Wikimedia. Given a version of an article (a revision ID for an article), the ORES API provides class probabilities for six of the grades in the [WikiProject article quality grading scheme](https://en.wikipedia.org/wiki/Wikipedia:Content_assessment#Grades) (FA, GA, B, C, Start, Stub). The ORES API also provides a grade prediction, which we will be extracting for use in later stages of this assignment.\n",
    "\n",
    "The ORES API does allow for the [grades of multiple articles to be predicted at once](https://ores.wikimedia.org/v3/#!/scoring/get_v3_scores_context), but there are limitations. First of all, there's a limit to how long a URL can be (2083 characters). Since each revision ID passed to the ORES API is 9 characters long and multiple revision IDs are separated by the \"|\" character, this limits us to passing ~200 Wikipedia articles to the ORES API with each call. Secondly, through trial and error, it seems like the ORES API provides its _own_ limit to the number of Wikipedia articles it can query within the same API call. This limit was found to be 140 Wikipedia articles, with any number of articles above this causing the API call to come back with a 503 Service Unavailable response.\n",
    "\n",
    "Due to the limit on revision IDs that can be passed to the ORES API with each call, we first separate the revision IDs found in the Wikipedia article CSV file into chunks no longer than 140 IDs. We then make an API call for each of these chunks and save each article's predicted grade/quality. There are some cases where predictions can't be made either because the revision ID can't be found (RevisionNotFound error) or the Wikipedia article has been deleted (TextDeleted error). We ignore Wikipedia articles where quality predictions cannot be made in later stages of this assignment. Since ~300 revision ID chunks are created from the Wikipedia article CSV file and ~300 API calls are made, this step may take a couple minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338 revision ID chunks created\n"
     ]
    }
   ],
   "source": [
    "# maximum revision IDs allowed per API call, found through trial and error\n",
    "MAX_REV_IDS_PER_CALL = 140\n",
    "\n",
    "def create_string_chunk(rev_ids, chunk_list):\n",
    "    \"\"\"\n",
    "    Transforms a list of revision IDs into a string separated by \"|\" characters to be passed to a single API call.\n",
    "    Adds the revision ID string chunk to a list of all revision ID string chunks, representing the number of API calls.\n",
    "    Clears the original list of revision IDs so we can start creating the next list of revision IDs.\n",
    "    \"\"\"\n",
    "    rev_ids_string = \"|\".join(rev_ids)\n",
    "    chunk_list.append(rev_ids_string)\n",
    "    rev_ids.clear()\n",
    "\n",
    "rev_ids_string_chunks = []\n",
    "with open(\"data/page_data.csv\", \"r\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    is_header = True\n",
    "    tmp_rev_ids = []\n",
    "    for _, _, rev_id in csv_reader:\n",
    "        # ignore header row\n",
    "        if is_header:\n",
    "            is_header = False\n",
    "            continue\n",
    "        tmp_rev_ids.append(rev_id)\n",
    "        # if we've accumulated the maximum number of revision IDs allowed for an API call, transform the revision IDs\n",
    "        # into a string to pass as a parameter to an API call\n",
    "        if len(tmp_rev_ids) == MAX_REV_IDS_PER_CALL:\n",
    "            create_string_chunk(tmp_rev_ids, rev_ids_string_chunks)\n",
    "    # transform all leftover revision IDs into a string\n",
    "    if len(tmp_rev_ids) > 0:\n",
    "        create_string_chunk(tmp_rev_ids, rev_ids_string_chunks)\n",
    "            \n",
    "print(\"{} revision ID chunks created\".format(len(rev_ids_string_chunks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n",
      "Article quality predictions retrieved\n"
     ]
    }
   ],
   "source": [
    "# documentation found here: https://ores.wikimedia.org/v3/#!/scoring/get_v3_scores_context\n",
    "ORES_ENDPOINT = \"https://ores.wikimedia.org/v3/scores/{context}?models={model}&revids={revids}\"\n",
    "\n",
    "predictions = {}\n",
    "for rev_ids_string in rev_ids_string_chunks:\n",
    "    ores_params = {\n",
    "        \"context\": \"enwiki\",\n",
    "        \"model\": \"wp10\",\n",
    "        \"revids\": rev_ids_string\n",
    "    }\n",
    "    response = requests.get(ORES_ENDPOINT.format(**ores_params))\n",
    "    # raise an AssertionError if the API call does not come back successfully\n",
    "    assert response.status_code == 200, \"API call came back with status code: {}\".format(response.status_code)\n",
    "    print(\"*\", end=\"\")\n",
    "    json = response.json()\n",
    "    scores = json[\"enwiki\"][\"scores\"]\n",
    "    for rev_id in scores.keys():\n",
    "        model = scores[rev_id][\"wp10\"]\n",
    "        # some queries by the API don't return predictions because the revision ID wasn't found (RevisionNotFound error)\n",
    "        # or the Wikipedia article has since been deleted (TextDeleted error), we will not save these revision IDs in\n",
    "        # the predictions map\n",
    "        if \"score\" in model:\n",
    "            prediction = model[\"score\"][\"prediction\"]\n",
    "            predictions[rev_id] = prediction\n",
    "\n",
    "print(\"\\nArticle quality predictions retrieved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Merging the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we effectively have three data sources (Wikipedia articles CSV file, countries CSV file, article quality predictions) that can be linked with each other, we will merge the data sources into one CSV outfile (\"article_qualities.csv\").\n",
    "\n",
    "The schema for the CSV outfile is as follows:\n",
    "\n",
    "|column         |description                                         |\n",
    "|---------------|----------------------------------------------------|\n",
    "|country        |country of politician the Wikipedia article is about|\n",
    "|article_name   |name of Wikipedia article                           |\n",
    "|revision_id    |revision ID of last edit to Wikipedia article       |\n",
    "|article_quality|predicted grade/quality of Wikipedia article        |\n",
    "|population     |population of country in millions of people         |\n",
    "\n",
    "Before merging the three data sources, we have to take into account mismatching country names between the articles CSV file and the countries CSV file. I've gone through the articles CSV file, saved each country that didn't have a match in the countries CSV file and tallied up how many times that mismatching country name appeared in the articles CSV file. For mismatching country names that appeared more than 30 times (arbitrary number to make sure the number of manual country name mappings wasn't too small or large) in the articles CSV file and had a slightly different country name in the countries CSV file, I've created a manual mapping between the similar country names (e.g. \"Czech Republic\" in the articles CSV file maps to \"Czechia\" in the countries CSV file) so we are able to merge Wikipedia article data from these countries. The final country name that is used in the outfile is the country name seen in the countries CSV file. All Wikipedia articles with country names that still have no match in the countries CSV file will be ignored during later stages of this assignment. All Wikipedia articles where we weren't able to make quality predictions for will also be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the country populations CSV file into memory since its small, makes it easier to merge the three data sources\n",
    "# together\n",
    "\n",
    "populations = {}\n",
    "with open(\"data/WPDS_2018_data.csv\", \"r\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    is_header = True\n",
    "    for country, population in csv_reader:\n",
    "        # ignore header row\n",
    "        if is_header:\n",
    "            is_header = False\n",
    "            continue\n",
    "        # remove commas from populations (e.g. 1,284 -> 1284) to make it easier to convert populations to floats at a\n",
    "        # later stage\n",
    "        populations[country] = population.replace(\",\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mappings between country names (country name in articles CSV file -> country name in countries CSV file) that\n",
    "# slightly differ in each CSV file, map only contains common mismatched country names\n",
    "COMMON_MISMATCHING_COUNTRIES = {\n",
    "    \"Czech Republic\": \"Czechia\",\n",
    "    \"Hondura\": \"Honduras\",\n",
    "    \"Congo, Dem. Rep. of\": \"Congo, Dem. Rep.\",\n",
    "    \"Salvadoran\": \"El Salvador\",\n",
    "    \"South Korean\": \"Korea, South\",\n",
    "    \"Ivorian\": \"Cote d'Ivoire\",\n",
    "    \"Samoan\": \"Samoa\",\n",
    "    \"Saint Lucian\": \"Saint Lucia\",\n",
    "    \"East Timorese\": \"Timor-Leste\",\n",
    "    \"Saint Kitts and Nevis\": \"St. Kitts-Nevis\",\n",
    "    \"Swaziland\": \"eSwatini\",\n",
    "}\n",
    "\n",
    "with open(\"data/page_data.csv\", \"r\") as csv_file_read:\n",
    "    with open(\"article_qualities.csv\", \"w\") as csv_file_write:\n",
    "        csv_reader = csv.reader(csv_file_read)\n",
    "        csv_writer = csv.writer(csv_file_write)\n",
    "        # write header row\n",
    "        csv_writer.writerow([\"country\", \"article_name\", \"revision_id\", \"article_quality\", \"population\"])\n",
    "        is_header = True\n",
    "        for page, country, rev_id in csv_reader:\n",
    "            # ignore header row when reading\n",
    "            if is_header:\n",
    "                is_header = False\n",
    "                continue\n",
    "            # if possible, map the country name provided by the articles CSV file\n",
    "            country = COMMON_MISMATCHING_COUNTRIES.get(country, country)\n",
    "            # write to the CSV outfile only if we were able to predict the article's quality and the country name\n",
    "            # matches with a country name in the countries CSV file\n",
    "            if rev_id in predictions.keys() and country in populations.keys():\n",
    "                # join the article's quality prediction\n",
    "                quality_prediction = predictions[rev_id]\n",
    "                # join the country's population in millions of people\n",
    "                population = populations[country]\n",
    "                csv_writer.writerow([country, page, rev_id, quality_prediction, population])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Computing the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify potential biases with English Wikipedia articles about politicians across countries, we will use two different metrics.\n",
    "\n",
    "**articles-per-population**\n",
    "\n",
    "This metric will be displayed in the \"articles/million people\" column in the tables below. For each country, it represents the number of articles about politicians per one million people of country population.\n",
    "\n",
    "**proportion of high-quality articles**\n",
    "\n",
    "This metric will be displayed in the \"perc. of high quality articles\" column in the tables below. For each country, it represents the proportion of articles about politicians that were predicted to be either a featured article (FA) or a good article (GA). The proportion is represented as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the outputted CSV file as a pandas.DataFrame\n",
    "articles_df = pandas.read_csv(\"article_qualities.csv\")\n",
    "\n",
    "# add a boolean column determining whether the articles was predicted to be of high quality (FA or GA)\n",
    "articles_df[\"high_quality_article\"] = (articles_df[\"article_quality\"] == \"FA\") | (articles_df[\"article_quality\"] == \"GA\")\n",
    "\n",
    "# aggregate the original DataFrame to calculate the number of articles for each country\n",
    "article_count_df = pandas.DataFrame({\"article count\": articles_df.groupby([\"country\", \"population\"]).size()}).reset_index()\n",
    "\n",
    "# aggregate the original DataFrame to calculate the number of high quality articles for each country\n",
    "hq_article_count_df = pandas.DataFrame({\"high quality article count\": articles_df.groupby([\"country\", \"population\"])[\"high_quality_article\"].sum()}).reset_index()\n",
    "\n",
    "# merge the two aggregated DataFrames together\n",
    "countries_df = article_count_df.merge(hq_article_count_df)\n",
    "\n",
    "# convert a count column from float to integer\n",
    "countries_df[\"high quality article count\"] = countries_df[\"high quality article count\"].astype(int)\n",
    "\n",
    "# add a column representing the number of articles per one million people\n",
    "countries_df[\"articles/million people\"] = countries_df[\"article count\"]/countries_df[\"population\"]\n",
    "\n",
    "# add a column representing the proportion of high quality articles as a percentage\n",
    "countries_df[\"perc. of high quality articles\"] = (countries_df[\"high quality article count\"]/countries_df[\"article count\"])*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 highest ranked countries in terms of articles-per-population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>article count</th>\n",
       "      <th>high quality article count</th>\n",
       "      <th>articles/million people</th>\n",
       "      <th>perc. of high quality articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>9.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Nauru</td>\n",
       "      <td>0.01</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>5300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>San Marino</td>\n",
       "      <td>0.03</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>2733.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Monaco</td>\n",
       "      <td>0.04</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Liechtenstein</td>\n",
       "      <td>0.04</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>725.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>St. Kitts-Nevis</td>\n",
       "      <td>0.05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Tonga</td>\n",
       "      <td>0.10</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>630.000000</td>\n",
       "      <td>1.587302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Marshall Islands</td>\n",
       "      <td>0.06</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>616.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>0.40</td>\n",
       "      <td>206</td>\n",
       "      <td>2</td>\n",
       "      <td>515.000000</td>\n",
       "      <td>0.970874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>0.08</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>425.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              country  population  article count  high quality article count  \\\n",
       "175            Tuvalu        0.01             55                           5   \n",
       "120             Nauru        0.01             53                           0   \n",
       "142        San Marino        0.03             82                           0   \n",
       "113            Monaco        0.04             40                           0   \n",
       "98      Liechtenstein        0.04             29                           0   \n",
       "158   St. Kitts-Nevis        0.05             32                           0   \n",
       "170             Tonga        0.10             63                           1   \n",
       "108  Marshall Islands        0.06             37                           0   \n",
       "73            Iceland        0.40            206                           2   \n",
       "3             Andorra        0.08             34                           0   \n",
       "\n",
       "     articles/million people  perc. of high quality articles  \n",
       "175              5500.000000                        9.090909  \n",
       "120              5300.000000                        0.000000  \n",
       "142              2733.333333                        0.000000  \n",
       "113              1000.000000                        0.000000  \n",
       "98                725.000000                        0.000000  \n",
       "158               640.000000                        0.000000  \n",
       "170               630.000000                        1.587302  \n",
       "108               616.666667                        0.000000  \n",
       "73                515.000000                        0.970874  \n",
       "3                 425.000000                        0.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_df.sort_values(by=\"articles/million people\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table is quite unexciting since it's entirely made up of countries with less than half a million people. Below is another table displaying the 10 highest ranked countries in terms of articles-per-population, but filtering out countries with fewer than 100 articles about politicians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>article count</th>\n",
       "      <th>high quality article count</th>\n",
       "      <th>articles/million people</th>\n",
       "      <th>perc. of high quality articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>0.4</td>\n",
       "      <td>206</td>\n",
       "      <td>2</td>\n",
       "      <td>515.000000</td>\n",
       "      <td>0.970874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>0.6</td>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Fiji</td>\n",
       "      <td>0.9</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>221.111111</td>\n",
       "      <td>0.502513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Malta</td>\n",
       "      <td>0.5</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>4.9</td>\n",
       "      <td>790</td>\n",
       "      <td>12</td>\n",
       "      <td>161.224490</td>\n",
       "      <td>1.518987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2.9</td>\n",
       "      <td>460</td>\n",
       "      <td>4</td>\n",
       "      <td>158.620690</td>\n",
       "      <td>0.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Norway</td>\n",
       "      <td>5.3</td>\n",
       "      <td>658</td>\n",
       "      <td>6</td>\n",
       "      <td>124.150943</td>\n",
       "      <td>0.911854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Moldova</td>\n",
       "      <td>3.5</td>\n",
       "      <td>426</td>\n",
       "      <td>0</td>\n",
       "      <td>121.714286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Estonia</td>\n",
       "      <td>1.3</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>117.692308</td>\n",
       "      <td>0.653595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Finland</td>\n",
       "      <td>5.5</td>\n",
       "      <td>572</td>\n",
       "      <td>0</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         country  population  article count  high quality article count  \\\n",
       "73       Iceland         0.4            206                           2   \n",
       "100   Luxembourg         0.6            180                           1   \n",
       "57          Fiji         0.9            199                           1   \n",
       "107        Malta         0.5            103                           0   \n",
       "123  New Zealand         4.9            790                          12   \n",
       "1        Albania         2.9            460                           4   \n",
       "127       Norway         5.3            658                           6   \n",
       "112      Moldova         3.5            426                           0   \n",
       "54       Estonia         1.3            153                           1   \n",
       "58       Finland         5.5            572                           0   \n",
       "\n",
       "     articles/million people  perc. of high quality articles  \n",
       "73                515.000000                        0.970874  \n",
       "100               300.000000                        0.555556  \n",
       "57                221.111111                        0.502513  \n",
       "107               206.000000                        0.000000  \n",
       "123               161.224490                        1.518987  \n",
       "1                 158.620690                        0.869565  \n",
       "127               124.150943                        0.911854  \n",
       "112               121.714286                        0.000000  \n",
       "54                117.692308                        0.653595  \n",
       "58                104.000000                        0.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_df[countries_df[\"article count\"] >= 100].sort_values(by=\"articles/million people\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 lowest ranked countries in terms of articles-per-population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>article count</th>\n",
       "      <th>high quality article count</th>\n",
       "      <th>articles/million people</th>\n",
       "      <th>perc. of high quality articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>India</td>\n",
       "      <td>1371.3</td>\n",
       "      <td>986</td>\n",
       "      <td>14</td>\n",
       "      <td>0.719026</td>\n",
       "      <td>1.419878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Indonesia</td>\n",
       "      <td>265.2</td>\n",
       "      <td>214</td>\n",
       "      <td>8</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>3.738318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>China</td>\n",
       "      <td>1393.8</td>\n",
       "      <td>1135</td>\n",
       "      <td>33</td>\n",
       "      <td>0.814321</td>\n",
       "      <td>2.907489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>32.9</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0.881459</td>\n",
       "      <td>3.448276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>107.5</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>17.7</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1.412429</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Korea, North</td>\n",
       "      <td>25.6</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>1.523438</td>\n",
       "      <td>17.948718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Congo, Dem. Rep.</td>\n",
       "      <td>84.3</td>\n",
       "      <td>142</td>\n",
       "      <td>8</td>\n",
       "      <td>1.684460</td>\n",
       "      <td>5.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>66.2</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>1.691843</td>\n",
       "      <td>2.678571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>166.4</td>\n",
       "      <td>323</td>\n",
       "      <td>3</td>\n",
       "      <td>1.941106</td>\n",
       "      <td>0.928793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              country  population  article count  high quality article count  \\\n",
       "74              India      1371.3            986                          14   \n",
       "75          Indonesia       265.2            214                           8   \n",
       "34              China      1393.8           1135                          33   \n",
       "182        Uzbekistan        32.9             29                           1   \n",
       "55           Ethiopia       107.5            105                           1   \n",
       "187            Zambia        17.7             25                           0   \n",
       "87       Korea, North        25.6             39                           7   \n",
       "38   Congo, Dem. Rep.        84.3            142                           8   \n",
       "167          Thailand        66.2            112                           3   \n",
       "13         Bangladesh       166.4            323                           3   \n",
       "\n",
       "     articles/million people  perc. of high quality articles  \n",
       "74                  0.719026                        1.419878  \n",
       "75                  0.806938                        3.738318  \n",
       "34                  0.814321                        2.907489  \n",
       "182                 0.881459                        3.448276  \n",
       "55                  0.976744                        0.952381  \n",
       "187                 1.412429                        0.000000  \n",
       "87                  1.523438                       17.948718  \n",
       "38                  1.684460                        5.633803  \n",
       "167                 1.691843                        2.678571  \n",
       "13                  1.941106                        0.928793  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_df.sort_values(by=\"articles/million people\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 highest ranked countries in terms of proportion of high-quality articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>article count</th>\n",
       "      <th>high quality article count</th>\n",
       "      <th>articles/million people</th>\n",
       "      <th>perc. of high quality articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Korea, North</td>\n",
       "      <td>25.60</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>1.523438</td>\n",
       "      <td>17.948718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>33.40</td>\n",
       "      <td>119</td>\n",
       "      <td>16</td>\n",
       "      <td>3.562874</td>\n",
       "      <td>13.445378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Central African Republic</td>\n",
       "      <td>4.70</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>14.468085</td>\n",
       "      <td>11.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Romania</td>\n",
       "      <td>19.50</td>\n",
       "      <td>348</td>\n",
       "      <td>40</td>\n",
       "      <td>17.846154</td>\n",
       "      <td>11.494253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Mauritania</td>\n",
       "      <td>4.50</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>11.555556</td>\n",
       "      <td>9.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>9.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bhutan</td>\n",
       "      <td>0.80</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>9.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Dominica</td>\n",
       "      <td>0.07</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>171.428571</td>\n",
       "      <td>8.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>United States</td>\n",
       "      <td>328.00</td>\n",
       "      <td>1092</td>\n",
       "      <td>82</td>\n",
       "      <td>3.329268</td>\n",
       "      <td>7.509158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Benin</td>\n",
       "      <td>11.50</td>\n",
       "      <td>94</td>\n",
       "      <td>7</td>\n",
       "      <td>8.173913</td>\n",
       "      <td>7.446809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      country  population  article count  \\\n",
       "87               Korea, North       25.60             39   \n",
       "144              Saudi Arabia       33.40            119   \n",
       "31   Central African Republic        4.70             68   \n",
       "137                   Romania       19.50            348   \n",
       "109                Mauritania        4.50             52   \n",
       "175                    Tuvalu        0.01             55   \n",
       "19                     Bhutan        0.80             33   \n",
       "47                   Dominica        0.07             12   \n",
       "180             United States      328.00           1092   \n",
       "18                      Benin       11.50             94   \n",
       "\n",
       "     high quality article count  articles/million people  \\\n",
       "87                            7                 1.523438   \n",
       "144                          16                 3.562874   \n",
       "31                            8                14.468085   \n",
       "137                          40                17.846154   \n",
       "109                           5                11.555556   \n",
       "175                           5              5500.000000   \n",
       "19                            3                41.250000   \n",
       "47                            1               171.428571   \n",
       "180                          82                 3.329268   \n",
       "18                            7                 8.173913   \n",
       "\n",
       "     perc. of high quality articles  \n",
       "87                        17.948718  \n",
       "144                       13.445378  \n",
       "31                        11.764706  \n",
       "137                       11.494253  \n",
       "109                        9.615385  \n",
       "175                        9.090909  \n",
       "19                         9.090909  \n",
       "47                         8.333333  \n",
       "180                        7.509158  \n",
       "18                         7.446809  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_df.sort_values(by=\"perc. of high quality articles\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 lowest ranked countries in terms of proportion of high-quality articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are more than 10 countries with zero high quality articles about politicians, I've also sorted this table by the volume of articles about politicians. So, countries that have no high quality articles about politicians but have a large number of _articles_ (regardless of quality) about politicians will appear higher in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>article count</th>\n",
       "      <th>high quality article count</th>\n",
       "      <th>articles/million people</th>\n",
       "      <th>perc. of high quality articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Finland</td>\n",
       "      <td>5.5</td>\n",
       "      <td>572</td>\n",
       "      <td>0</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>11.4</td>\n",
       "      <td>523</td>\n",
       "      <td>0</td>\n",
       "      <td>45.877193</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Moldova</td>\n",
       "      <td>3.5</td>\n",
       "      <td>426</td>\n",
       "      <td>0</td>\n",
       "      <td>121.714286</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>8.5</td>\n",
       "      <td>407</td>\n",
       "      <td>0</td>\n",
       "      <td>47.882353</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Nepal</td>\n",
       "      <td>29.7</td>\n",
       "      <td>361</td>\n",
       "      <td>0</td>\n",
       "      <td>12.154882</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Honduras</td>\n",
       "      <td>9.0</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Uganda</td>\n",
       "      <td>44.1</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>4.263039</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>5.0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Tunisia</td>\n",
       "      <td>11.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>12.068966</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Slovakia</td>\n",
       "      <td>5.4</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>22.037037</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         country  population  article count  high quality article count  \\\n",
       "58       Finland         5.5            572                           0   \n",
       "16       Belgium        11.4            523                           0   \n",
       "112      Moldova         3.5            426                           0   \n",
       "162  Switzerland         8.5            407                           0   \n",
       "121        Nepal        29.7            361                           0   \n",
       "71      Honduras         9.0            189                           0   \n",
       "176       Uganda        44.1            188                           0   \n",
       "39    Costa Rica         5.0            150                           0   \n",
       "172      Tunisia        11.6            140                           0   \n",
       "150     Slovakia         5.4            119                           0   \n",
       "\n",
       "     articles/million people  perc. of high quality articles  \n",
       "58                104.000000                             0.0  \n",
       "16                 45.877193                             0.0  \n",
       "112               121.714286                             0.0  \n",
       "162                47.882353                             0.0  \n",
       "121                12.154882                             0.0  \n",
       "71                 21.000000                             0.0  \n",
       "176                 4.263039                             0.0  \n",
       "39                 30.000000                             0.0  \n",
       "172                12.068966                             0.0  \n",
       "150                22.037037                             0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_df.sort_values(by=[\"perc. of high quality articles\", \"article count\"], ascending=[True, False]).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Writeup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're looking at _English_ Wikipedia politician articles, I expect the more English-speaking a country is, the more articles-per-population and the higher proportion of high-quality articles, and vice versa. My theory is based on a few assumptions:\n",
    "\n",
    "1. The higher proportion of English-speaking residents in a country, the higher proportion of residents who contribute to English Wikipedia articles\n",
    "2. Wikipedians are more likely to edit politician articles for politicians in their country than politicians in other countries\n",
    "3. Wikipedians tend to have greater knowledge of politicians in their country than equivalent politicians in other countries, causing Wikipedians to write higher quality articles for politicians in their country\n",
    "\n",
    "I also expect the higher a country's standard of living is (I'm using the [IHDI metric](https://en.wikipedia.org/wiki/List_of_countries_by_inequality-adjusted_HDI) for a quantitative representation of this), the more articles-per-population and the higher proportion of high-quality articles, and vice versa. To go along with assumptions 2 and 3 above, this theory is based on a new assumption:\n",
    "\n",
    "1. The higher a country's inequality-adjusted human development index (IHDI), the higher proportion of residents who contribute to Wikipedia articles\n",
    "\n",
    "In summary, my theories are that English Wikipedia politician articles are biased in volume and quality towards predominantly English-speaking countries and countries with higher standards of living.\n",
    "\n",
    "It looks like a country's population heavily influences its rank according to the articles-per-population metric. Unfiltered, the top 10 countries according to this metric has a population of less than half a million people and the top 3 lowest countries according to this metric are 3 of the top 4 countries according to population. The United States has the 3rd highest population count in the world, but doesn't appear in the top 10 lowest countries according to the articles-per-population metric. Of the top 10 countries according to this metric (filtered), 7 are ranked in the top 30 of the IHDI metric and 5 have a >50% English-speaking population. Whereas, of the bottom 10 countries according to this metric, China has the highest ranking according to the IHDI metric (62) and none of the countries are predominantly English-speaking.\n",
    "\n",
    "Of the top 10 countries according to the proportion of high-quality articles metric, there are more countries that rank in the _bottom_ 30 according to the IHDI metric (3) than rank in the top 30 (United States). Also, only 2 of the top 10 countries according to this metric are predominantly English-speaking. Of the bottom 10 countries according to this metric, there are more countries that rank in the _top_ 30 according to the IHDI metric (4) then rank in the bottom 30 (Uganda). Also, 4 of the bottom 10 countries are predominantly English-speaking, more English-speaking countries than the top 10 countries according to the proportion of high-quality articles metric.\n",
    "\n",
    "I would say the theories of more English-speaking/more articles-per-population and higher standard of living/more articles-per-population were sufficiently supported. On the other hand, the theories related to the proportion of high-quality articles were not supported at all and the results were mostly opposite my original theories. From my limited knowledge of world government, my new theory is that the proportion of high-quality politician articles for a country is correlated with how \"controversial\" or how \"atypical\" the country's government is. The presence of North Korea and Saudi Arabia at the top of this metric supports the new theory. A case could be made that the inclusion of United States in the top 10 according to this metric also support the new theory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
